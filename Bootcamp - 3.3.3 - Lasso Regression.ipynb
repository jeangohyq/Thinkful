{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data again. Keep air quality data, drop the index column\n",
    "# and any missing data columns.\n",
    "df = pd.read_csv(\n",
    "    'https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Default.csv'\n",
    ").iloc[:,1:].dropna()\n",
    "\n",
    "# Recode strings to numeric.\n",
    "df['default'] = np.where(df['default']=='Yes', 1, 0)\n",
    "df['student'] = np.where(df['student']=='Yes', 1, 0)\n",
    "names = df.columns\n",
    "df = pd.DataFrame(preprocessing.scale(df), columns=names)\n",
    "\n",
    "# Define the training and test sizes.\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "\n",
    "Y_train = df_train['income'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "\n",
    "# Make some new features to capture potential quadratic and cubic\n",
    "# relationships between solar radiation and day or temperature.\n",
    "df_train['balance_student'] = df_train['balance'] * df_train['student']\n",
    "df_train['balance_default'] = df_train['balance'] * df_train['default']\n",
    "df_train['student_default'] = df_train['student'] * df_train['default']\n",
    "df_train['balance_sqrt'] = (df_train['balance'] + 100) ** .5\n",
    "df_train['balance2'] = (df_train['balance'] + 100) ** 2\n",
    "df_train['balance3'] = (df_train['balance'] + 100) ** 3\n",
    "\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "\n",
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['income'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n",
    "\n",
    "# Test the more complex model with larger coefficients.\n",
    "df_test['balance_student'] = df_test['balance'] * df_test['student']\n",
    "df_test['balance_default'] = df_test['balance'] * df_test['default']\n",
    "df_test['student_default'] = df_test['student'] * df_test['default']\n",
    "df_test['balance_sqrt'] = (df_test['balance'] + 100) ** .5\n",
    "df_test['balance2'] = (df_test['balance'] + 100) ** 2\n",
    "df_test['balance3'] = (df_test['balance'] + 100) ** 3\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² for the model with few features:\n",
      "0.450062579301\n",
      "\n",
      "Parameter estimates for the model with few features:\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n",
      "\n",
      "R² for the model with many features:\n",
      "0.443633767129\n",
      "\n",
      "Parameter estimates for the model with many features:\n",
      "[  0.00000000e+00  -3.89351238e-01   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00  -2.77688887e-04\n",
      "  -7.09158792e-07   3.48711577e+00]\n"
     ]
    }
   ],
   "source": [
    "#When alpa=.35, R² for the model with many features: 0.443633767129\n",
    "\n",
    "#Small number of parameters\n",
    "lass = linear_model.Lasso(alpha=0.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)\n",
    "\n",
    "#Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=0.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nR² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.445532251512\n",
      "0.438046634591\n"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot below of how R2 varies across different values of λ for ridge and lasso regression. \n",
    "#Use logic and code similar to the ridge regression demonstration above, \n",
    "#and base your plot on the X_train2 feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 6.863128803211902e-23 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 3.66801327188232e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 7.377185766677148e-17 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#Small number of parameters\n",
    "from sklearn import linear_model\n",
    "\n",
    "alpha_values = np.arange(0, 20, .2)\n",
    "lasso_scores = []\n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    lass = linear_model.Lasso(alpha=alpha) \n",
    "    lassfit = lass.fit(X_train2, Y_train)\n",
    "    lasso_scores.append(lass.score(X_train2, Y_train))\n",
    "\n",
    "    ridgeregr = linear_model.Ridge(alpha=alpha, fit_intercept=False)\n",
    "    ridgeregrfit = ridgeregr.fit(X_train2, Y_train)\n",
    "    ridge_scores.append(ridgeregr.score(X_train2, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57397331017147024, 0.57397206570731396, 0.57397141144908004, 0.57397055490050997, 0.5739695981426034, 0.5739686014514882, 0.57396760059545959, 0.57396661663415371, 0.57396566164168505, 0.57396474213658066, 0.57396386118106313, 0.57396301968910568, 0.57396221725162277, 0.573961452663313, 0.57396072426079092, 0.57396003013987518, 0.57395936829503236, 0.57395873670833697, 0.57395813340462221, 0.57395755648470892, 0.57395700414438955, 0.57395647468349109, 0.57395596650932434, 0.57395547813552616, 0.57395500817894773, 0.57395455535460349, 0.57395411847036581, 0.57395369642074523, 0.5739532881810131, 0.57395289280116346, 0.57395250940046183, 0.57395213716188542, 0.57395177532712915, 0.57395142319212489, 0.57395108010239548, 0.57395074544937064, 0.57395041866656316, 0.57395009922627549, 0.57394978663650176, 0.57394948043813221, 0.57394918020236796, 0.57394888552832191, 0.57394859604097592, 0.57394831138911973, 0.57394803124362359, 0.57394775529572306, 0.57394748325553502, 0.57394721485067834, 0.57394694982504113, 0.57394668793761572, 0.5739464289613363, 0.57394617268218351, 0.57394591889832602, 0.57394566741917008, 0.57394541806470745, 0.57394517066470452, 0.57394492505819172, 0.57394468109269403, 0.57394443862383582, 0.57394419751472503, 0.57394395763552775, 0.573943718862993, 0.57394348108007587, 0.57394324417555209, 0.57394300804364495, 0.5739427725837476, 0.57394253770004611, 0.57394230330131868, 0.57394206930061165, 0.57394183561501522, 0.57394160216543399, 0.57394136887639569, 0.5739411356757842, 0.57394090249474694, 0.57394066926744458, 0.57394043593091459, 0.57394020242493415, 0.57393996869184039, 0.57393973467642789, 0.57393950032580987, 0.57393926558929675, 0.57393903041830197, 0.57393879476619469, 0.57393855858825105, 0.57393832184153704, 0.57393808448482653, 0.57393784647851032, 0.57393760778453029, 0.57393736836628861, 0.57393712818860554, 0.57393688721763558, 0.57393664542080036, 0.57393640276675062, 0.57393615922528451, 0.57393591476732531, 0.57393566936485052, 0.57393542299085654, 0.57393517561929874, 0.57393492722506201, 0.57393467778392426]\n",
      "[0.57394444831554214, 0.53123523313557819, 0.4038148555303922, 0.19144674105687931, 0.026834134749037727, 0.026834134351719777, 0.026834133866108337, 0.026834133292204299, 0.026834132630007002, 0.026834131879516998, 0.026834131040733955, 0.026834130113657872, 0.026834129098289083, 0.026834127994627255, 0.026834126802672383, 0.02683412552242459, 0.026834124153884083, 0.026834122697050104, 0.02683412115192374, 0.0268341195185039, 0.026834117796791568, 0.026834115986785978, 0.026834114088487571, 0.026834112101896235, 0.026834110027011967, 0.026834107863834555, 0.026834105612364437, 0.026834103272601051, 0.026834100844545072, 0.026834098328196054, 0.026834095723553997, 0.026834093030619122, 0.026834090249391093, 0.026834087379870256, 0.026834084422056367, 0.02683408137594967, 0.026834078241549819, 0.026834075018857265, 0.026834071707871669, 0.02683406830859314, 0.026834064821021571, 0.026834061245157196, 0.026834057580999545, 0.026834053828549195, 0.02683404998780603, 0.026834046058769601, 0.026834042041440465, 0.0268340379358184, 0.026834033741903185, 0.026834029459695038, 0.02683402508919408, 0.02683402063040019, 0.026834016083313039, 0.026834011447933404, 0.026834006724260503, 0.026834001912294684, 0.026833997012035926, 0.026833992023484358, 0.026833986946639521, 0.026833981781502092, 0.026833976528071513, 0.026833971186347897, 0.026833965756331683, 0.0268339602380222, 0.02683395463141991, 0.026833948936524687, 0.026833943153336426, 0.026833937281855121, 0.026833931322081117, 0.026833925274014184, 0.026833919137654091, 0.026833912913001079, 0.026833906600055135, 0.026833900198816148, 0.026833893709284348, 0.026833887131459618, 0.026833880465341853, 0.026833873710931381, 0.02683386686822764, 0.026833859937231089, 0.026833852917941606, 0.026833845810359188, 0.02683383861448374, 0.02683383133031525, 0.026833823957853831, 0.026833816497099702, 0.02683380894805254, 0.026833801310712332, 0.026833793585079087, 0.026833785771153137, 0.026833777868933928, 0.02683376987842212, 0.026833761799617162, 0.026833753632519493, 0.026833745377128682, 0.026833737033444716, 0.026833728601467932, 0.026833720081198335, 0.026833711472635691, 0.026833702775780229]\n"
     ]
    }
   ],
   "source": [
    "print(ridge_scores)\n",
    "print(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD3CAYAAAA9vL6wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGOFJREFUeJzt3X1wVOX99/HPPmSTkAVpBvqDnxqK\nqakVpDGl/mCcwN07d24sUJhaIaEBbJGW2lK0BrC1Y4ghk4axD06pogw2OkAhkVbasWp7Z0oNTZE6\nwUXC4/hAxqJgeHBgF8gm2XP/EXJkTWRtze7m7PV+/bPZc51Nvjm7fHJxneucy2VZliUAgGO4k10A\nAODfQ3ADgMMQ3ADgMAQ3ADgMwQ0ADkNwA4DDeGPtEIlEVFlZqcOHD8vn86m6ulpjxoyx21966SU9\n+uijsixL48aN06pVq+RyueJaNACYLGaPu7GxUeFwWPX19SovL1dtba3dFgwG9fDDD+vxxx/XM888\no6uvvlpnzpyJa8EAYLqYPe6WlhYVFhZKkvLz89Xa2mq3vfrqq8rLy9OaNWv09ttva86cOcrOzo56\n/cWLF9Xa2qqRI0fK4/EMcPkAkHq6u7vV3t6u8ePHKyMjo097zOAOBoPy+/32c4/Ho66uLnm9Xp05\nc0a7d+/W9u3bNWTIEJWVlSk/P19jx461929tbVVZWdkA/ToAYI7Nmzdr4sSJfbbHDG6/369QKGQ/\nj0Qi8np7XjZ8+HDddNNNGjlypCRp4sSJOnjwYFRw97Zt3rxZo0aN+mS/BQAY4Pjx4yorK7Pz88Ni\nBndBQYF27Nih6dOnKxAIKC8vz24bN26cjhw5otOnT2vYsGHau3ev5s6dG/X63uGRUaNG6Zprrvkk\nvwsAGOWjhpdjBndxcbGam5tVWloqy7JUU1Ojuro65eTkqKioSOXl5Vq8eLEk6bbbbosKdgDAwIsZ\n3G63W1VVVVHbcnNz7a9nzJihGTNmDHxlAIB+cQEOADgMwQ0ADkNwA4DDxBzjTibLsvRR6/MMxqvq\nudQfQCIM6uDeV/u/tTE4Uc90/69klwJgAJnSx/m/N/6XnljQ9wKaT2pQB/d16ef0vSEHdM2470Rt\ntzT4lslk5c6PxqFBFIP+sdyc86m4fN9BHdz+sRPlf+Ovuuf/XJ/sUgBg0BjcJydH50vBE9LZd5Nd\nCQAMGoM7uP87v+fx3UBy6wCAQWRwB/eomySXW3qH4AaAXoM7uH1Z0og8etwAcJnBHdxSzzg3PW4A\nsA3+4P7vfCl4XDp3PNmVAMCgMPiDe/SlE5T0ugFAkhOCe9RNklyMcwPAJYM/uNP9PSco6XEDgCQn\nBLfUM85NjxsAJDkluEfnS+felc6dSHYlAJB0zghurqAEAJszgnvUBEku6Z1Xk10JACSdM4I73S8N\nv1Y69UayKwGApHNGcEtS5qeki+8nuwoASDrnBHfGcOkCwQ0AzgnuzOHShTPJrgIAks45wZ0xnKES\nAJCTgjvz0lCJQevVAUB/nBPcGcOlSKfUeT7ZlQBAUjknuDOH9zxyghKA4WKu8h6JRFRZWanDhw/L\n5/OpurpaY8aMsdurq6u1Z88eZWVlSZIee+wxDR06dOArzby0zP3F96Wrrh747w8ADhEzuBsbGxUO\nh1VfX69AIKDa2lqtW7fObt+/f782bNig7OzsuBaqDHrcACB9jKGSlpYWFRYWSpLy8/PV2tpqt0Ui\nEbW1tamiokKlpaXatm1b/CrtHSphZgkAw8XscQeDQfn9fvu5x+NRV1eXvF6vzp8/r/nz5+tb3/qW\nuru7tXDhQo0fP1433HDDwFdKjxsAJH2MHrff71coFLKfRyIReb09eZ+ZmamFCxcqMzNTfr9fkyZN\n0qFDh+JTKT1uAJD0MYK7oKBATU1NkqRAIKC8vDy77ejRo5o3b566u7vV2dmpPXv2aNy4cfGpNP0q\nSS563ACMF3OopLi4WM3NzSotLZVlWaqpqVFdXZ1ycnJUVFSk2bNna+7cuUpLS9Ps2bN1/fXXx6dS\nt1vKGMZl7wCMFzO43W63qqqqorbl5ubaXy9evFiLFy8e+Mr6w2XvAOCgC3CkDy57BwCDOSu46XED\ngMOCO/NT9LgBGM9hwU2PGwCcFdwZ3NoVAJwV3Jnc2hUAnBXcXPYOAA4Lbi57BwCHBTc9bgBwWHDb\nq+Bw2TsAczkruDMYKgEAZwU3604CgMOCu/fWrvS4ARjMWcHtdksZV9HjBmA0ZwW3xGXvAIznvODO\n4NauAMzmvOCmxw3AcM4LbnrcAAznvOCmxw3AcM4Lbm7tCsBwzgvu3lu7hkPJrgQAksJ5wc1l7wAM\n57zg5rJ3AIZzYHB/queRHjcAQzkvuLknNwDDOS+4WQUHgOGcF9z0uAEYznnBnT5M3NoVgMliBnck\nElFFRYVKSkq0YMECtbW19bvP4sWLtWXLlrgUGYVbuwIwXMzgbmxsVDgcVn19vcrLy1VbW9tnn0ce\neURnz56NS4H94rJ3AAaLGdwtLS0qLCyUJOXn56u1tTWq/cUXX5TL5bL3SYj0YdLFBP6hAIBBJGZw\nB4NB+f1++7nH41FXV5ck6ciRI3ruued0zz33xK/C/viypM7zif2ZADBIeGPt4Pf7FQp9cF+QSCQi\nr7fnZdu3b9eJEyd055136tixY0pLS9PVV1+tKVOmxK9iSUrLpMcNwFgxg7ugoEA7duzQ9OnTFQgE\nlJeXZ7etXLnS/nrt2rUaMWJE/ENbktKGSOeOx//nAMAgFDO4i4uL1dzcrNLSUlmWpZqaGtXV1Skn\nJ0dFRUWJqLGvtCEMlQAwVszgdrvdqqqqitqWm5vbZ78f/OAHA1dVLGmZUueFxP08ABhEnHcBjnSp\nx01wAzCTM4PbN6RnIQVWwQFgIGcGd1qmZHVL3Z3JrgQAEs6hwT2k55ETlAAM5NDgzux5ZJwbgIEc\nGtxZPY/0uAEYyKHB3dvjJrgBmMehwd07xs1QCQDzODS4L/W4w6Er7wcAKciZwe2jxw3AXM4MbqYD\nAjCYQ4Ob6YAAzOXQ4KbHDcBcBDcAOIwzg9ub0fPIUAkAAzkzuN1uyZtJjxuAkZwZ3NKlW7sS3ADM\n49zgZjEFAIZycHAzVALATA4PbnrcAMzj4ODOoscNwEgODm6GSgCYyeHBzVAJAPM4OLiH0OMGYCTn\nBjfzuAEYyrnBzTxuAIZycHBfOjlpWcmuBAASytnBbXVL3Z3JrgQAEsrBwZ3V89jJupMAzBIzuCOR\niCoqKlRSUqIFCxaora0tqn3z5s36+te/rjvuuEPPP/983Artg1VwABjKG2uHxsZGhcNh1dfXKxAI\nqLa2VuvWrZMknT59Wlu2bNGzzz6rjo4OzZgxQ1/5ylfkcrniXvgHiykQ3ADMErPH3dLSosLCQklS\nfn6+Wltb7bbs7Gxt375daWlpOnnypNLT0xMT2tJlPW6mBAIwS8zgDgaD8vv99nOPx6Ouri77udfr\n1aZNm1RSUqJZs2bFp8r++C71uJnLDcAwMYPb7/crFPrgBGAkEpHXGz3CMn/+fO3cuVOvvPKKXn75\n5YGvsj+sOwnAUDGDu6CgQE1NTZKkQCCgvLw8u+3NN9/U0qVLZVmW0tLS5PP55HYnaKIKJycBGCrm\nycni4mI1NzertLRUlmWppqZGdXV1ysnJUVFRkW644QaVlJTI5XKpsLBQt9xySyLqpscNwFgxg9vt\ndquqqipqW25urv310qVLtXTp0oGvLBaCG4ChHHwBDtMBAZjJwcHNdEAAZnJucHszeh7pcQMwjHOD\n2+3uGS4Jc68SAGZxbnBLLF8GwEgOD24WUwBgHocHNyu9AzCPw4ObBYMBmCcFgpuhEgBmcXhwM1QC\nwDzODm7fEG7rCsA4zg5uxrgBGMjhwc08bgDmcXhwc3ISgHlSILhDkmUluxIASBiHB3emZEWk7nCy\nKwGAhHF4cLOYAgDzODy4WXcSgHmcHdy+rJ5H5nIDMIizg5tVcAAYKEWCm6ESAOZweHBzchKAeQhu\nAHCYFAluhkoAmMPhwc3JSQDmcXhw0+MGYB5nB7fvUnCHQ8mtAwASyNnB7c3oeaTHDcAg3lg7RCIR\nVVZW6vDhw/L5fKqurtaYMWPs9qeeekp/+tOfJElTp07V0qVL41fth7lcLKYAwDgxe9yNjY0Kh8Oq\nr69XeXm5amtr7ba3335bf/zjH7V161Y1NDTo73//uw4dOhTXgvtgMQUAhonZ425paVFhYaEkKT8/\nX62trXbbqFGjtGHDBnk8HklSV1eX0tPT41TqR0jLoscNwCgxe9zBYFB+v99+7vF41NXVJUlKS0tT\ndna2LMvSmjVrdOONN2rs2LHxq7Y/rPQOwDAxg9vv9ysU+mDWRiQSkdf7QUe9o6NDy5cvVygU0qpV\nq+JT5ZUwVALAMDGDu6CgQE1NTZKkQCCgvLw8u82yLH3ve9/T5z73OVVVVdlDJgmVNoTbugIwSswx\n7uLiYjU3N6u0tFSWZammpkZ1dXXKyclRJBLRP//5T4XDYe3cuVOSdN999+nmm2+Oe+E2X5YUak/c\nzwOAJIsZ3G63W1VVVVHbcnNz7a/37ds38FX9O9L90pm3klsDACSQsy/AkSSfX+oIJrsKAEgY5wd3\n+jApTHADMEcKBLe/J7gjkWRXAgAJ4fzg9l2aY06vG4AhnB/c6QQ3ALOkQHAP63nkBCUAQzg/uHuH\nSjrOJbcOAEgQ5we3PVRCcAMwg/OD2+5xM1QCwAzOD+70oT2PnJwEYIjUCW7GuAEYwvnBzclJAIZx\nfnCnZUouN0MlAIzh/OB2uSTfUE5OAjCG84Nb6hnnZqgEgCFSJLj9zOMGYIzUCG7uyQ3AIKkR3L23\ndgUAA6RIcDPGDcAcqRHczCoBYJDUCG5OTgIwSGoEd+/JSctKdiUAEHepEdzpQyWrW+q6mOxKACDu\nUie4JU5QAjBCagQ3N5oCYJDUCG4WDAZgkBQJ7t6hEoIbQOpLjeD2McYNwBwxgzsSiaiiokIlJSVa\nsGCB2tra+uxz+vRpTZs2TR0dHXEpMiaGSgAYJGZwNzY2KhwOq76+XuXl5aqtrY1q37lzpxYtWqT2\n9va4FRkTJycBGCRmcLe0tKiwsFCSlJ+fr9bW1uhv4Harrq5Ow4cPj0+FHwc9bgAG8cbaIRgMyu/3\n2889Ho+6urrk9fa89NZbb41fdR8XPW4ABonZ4/b7/QqFQvbzSCRih/ag4fZIaVnMKgFghJjBXVBQ\noKamJklSIBBQXl5e3Iv6j3CjKQCGiNl1Li4uVnNzs0pLS2VZlmpqalRXV6ecnBwVFRUlosaPh1Vw\nABgiZnC73W5VVVVFbcvNze2z31//+teBq+o/wWIKAAyRGhfgSD3BzawSAAZIneBmqASAIVInuDk5\nCcAQKRTcjHEDMEPqBDdDJQAMkTrBnT5U6u6QujuTXQkAxFXqBDeXvQMwROoEdzrBDcAMKRTclxZT\nYC43gBSXOsHtY/kyAGZIneC278nNUAmA1JY6wW2fnKTHDSC1pU5wp7NgMAAzpF5wc3ISQIpLneBm\nqASAIVInuL0+yePj5CSAlJc6wS1xoykARkit4OZGUwAMkFrBzSo4AAyQWsHt8zNUAiDlxVws2FHS\nh0qnXpf2P5vsSgBA+q+bpBGfHfBvm1rBfdXV0uv/T3rmm8muBACka/9HuusvA/5tUyu4v/Kw9D/f\nTXYVANDjqmvi8m1TK7i9PunTn092FQAQV6l1chIADEBwA4DDENwA4DAENwA4TMzgjkQiqqioUElJ\niRYsWKC2trao9oaGBt1+++2aO3euduzYEbdCAQA9Ys4qaWxsVDgcVn19vQKBgGpra7Vu3TpJUnt7\nuzZu3Kjf/e536ujo0De+8Q3deuut8vl8cS8cAEwVM7hbWlpUWFgoScrPz1dra6vd9tprr+nmm2+W\nz+eTz+dTTk6ODh06pAkTJtj7dHd3S5KOHz8+0LUDQErqzcve/PywmMEdDAbl9/vt5x6PR11dXfJ6\nvQoGgxo6dKjdlpWVpWAw+iZP7e3tkqSysrJ/v3oAMFh7e7vGjBnTZ3vM4Pb7/QqFQvbzSCQir9fb\nb1soFIoKckkaP368Nm/erJEjR8rj8fzHvwAAmKK7u1vt7e0aP358v+0xg7ugoEA7duzQ9OnTFQgE\nlJeXZ7dNmDBBjzzyiDo6OhQOh/XGG29EtUtSRkaGJk6c+Al/DQAwS3897V4uy7KsK704EomosrJS\nR44ckWVZqqmpUVNTk3JyclRUVKSGhgbV19fLsiwtWbJE06ZNG/BfAADwgZjBnQi9fxwOHz4sn8+n\n6urqqL82DQ0N2rp1q7xer+6++259+ctfTlhtnZ2deuCBB3Ts2DGFw2HdfffdKioqstufeuopPfPM\nM8rOzpYkPfTQQ7ruuusSUtvXvvY1+/zDNddco5/+9Kd2WzKP2e9//3s9+2zPrXU7Ojp08OBBNTc3\na9iwYZKk6upq7dmzR1lZWZKkxx57rM8Q20Dbu3evfvazn2njxo1qa2vTj370I7lcLl1//fVatWqV\n3O4PZsZevHhRK1as0KlTp5SVlaU1a9bY72886zp48KBWr14tj8cjn8+nNWvWaMSIEVH7X+k9j2dt\nBw4c0JIlS/SZz3xGkjRv3jxNnz7d3jdZx+yHP/yhTp48KUk6duyYvvCFL+iXv/ylva9lWZoyZYpd\nd35+vsrLywe8pv5y4rOf/Wz8PmfWIPDnP//Zuv/++y3LsqxXX33V+u53v2u3vffee9bMmTOtjo4O\n6+zZs/bXibJt2zarurrasizLOnPmjDV16tSo9vLycmvfvn0Jq6fXxYsXrdmzZ/fbluxjdrnKykpr\n69atUdtKS0utU6dOJayG9evXWzNnzrTmzJljWZZlLVmyxHr55Zcty7KsBx980PrLX/4Stf9vfvMb\n61e/+pVlWZb13HPPWatXr05IXWVlZdaBAwcsy7KsLVu2WDU1NVH7X+k9j3dtDQ0N1pNPPvmR+yfr\nmPV6//33rVmzZlknTpyI2n706FFryZIlcanlcv3lRDw/Z4PiysmPO+Vw6NCh9pTDRLntttt0zz33\nSOr56/3hE6z79+/X+vXrNW/ePD3xxBMJq+vQoUO6cOGCFi1apIULFyoQCNhtyT5mvfbt26fXX39d\nJSUl9rZIJKK2tjZVVFSotLRU27Zti3sdOTk5Wrt2rf18//79uuWWWyRJU6ZM0T/+8Y+o/S//PE6Z\nMkW7du1KSF2/+MUv9PnP99zdsru7W+np6VH7X+k9j3dtra2t+tvf/qaysjI98MADfWaPJeuY9Vq7\ndq3mz5+vT3/601Hb9+/frxMnTmjBggX69re/rTfffDMudfWXE/H8nA2K4P6oKYe9bbGmHMZTVlaW\n/H6/gsGgli1bpnvvvTeqfcaMGaqsrNTTTz+tlpaWhF09mpGRobvuuktPPvmkHnroIS1fvnzQHLNe\nTzzxhL7//e9HbTt//rzmz5+vhx9+WBs2bNBvf/vbuP9RmTZtmj0TSur5h+VyuST1HJtz56KXu7v8\n+PXXHq+6ekNnz5492rRpk775zW9G7X+l9zzetU2YMEErV67U5s2bde211+rRRx+N2j9Zx0ySTp06\npV27dun222/vs//IkSP1ne98Rxs3btSSJUu0YsWKuNTVX07E83M2KIL7k045jLd3331XCxcu1OzZ\ns/XVr37V3m5Zlu68805lZ2fL5/Np6tSpOnDgQEJqGjt2rGbNmiWXy6WxY8dq+PDh9pz5wXDMzp49\nq7feekuTJk2K2p6ZmamFCxcqMzNTfr9fkyZNSvj/Bi4fZwyFQvbYe6/Lj19/7fH0/PPPa9WqVVq/\nfn2f8c4rvefxVlxcbE9NKy4u7vM5T+Yxe/HFFzVz5sx+pxuPHz/ePic1ceJEvffee7LidFrvwzkR\nz8/ZoAjugoICNTU1SVK/Uw5bWlrU0dGhc+fO9TvlMJ5OnjypRYsWacWKFbrjjjui2oLBoGbOnKlQ\nKCTLsrR79+6PnHc50LZt26ba2lpJ0okTJxQMBjVy5EhJyT9mkvTKK69o8uTJfbYfPXpU8+bNU3d3\ntzo7O7Vnzx6NGzcuobXdeOON2r17tySpqampz3TVgoICvfTSS3b7F7/4xYTU9Yc//EGbNm3Sxo0b\nde211/Zpv9J7Hm933XWXXnvtNUnSrl27+rxnyTpmvfVMmTKl37Zf//rXevrppyX1DDWNHj3a7gUP\npP5yIp6fs0E1q2QwTjmsrq7WCy+8EDVTZM6cObpw4YJKSkq0fft2bdy4UT6fT5MnT9ayZcsSUlc4\nHNaPf/xjvfPOO3K5XFq+fLn27t07KI6ZJG3YsEFer9f+735dXZ1d24YNG/TCCy8oLS1Ns2fP1rx5\n8+Jez7/+9S/dd999amho0FtvvaUHH3xQnZ2duu6661RdXS2Px6NFixbp8ccfV3d3t+6//361t7cr\nLS1NP//5z+MWkL11bdmyRZMnT9bo0aPtnteXvvQlLVu2TCtXrtS9996rESNG9HnPCwoK4lLX5bU1\nNDRo//79Wr16tdLS0jRixAitXr1afr8/qcesoaFBUs9w5ZYtW6J6rL11XbhwQStWrND58+fl8XhU\nUVGh3NzcAa+pv5z4yU9+ourq6rh8zgZFcAMAPr5BMVQCAPj4CG4AcBiCGwAchuAGAIchuAHAYQhu\nAHAYghsAHIbgBgCH+f89L6rGBZ4NcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116487048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alpha_values, ridge_scores)\n",
    "plt.plot(alpha_values, lasso_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For lasso, as regularization increases, coefficients get closer to zero.\n",
    "#Lasso takes out features and it's now using less features to predict the model. \n",
    "#Ridge works extremely well with correlated features, \n",
    "#while lasso is efficient when dealing with unmanageable large feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
